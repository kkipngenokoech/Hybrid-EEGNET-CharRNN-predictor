{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Get Necessary Packages"
      ],
      "metadata": {
        "id": "o4jgnVy0w_ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import cheby1, filtfilt, resample\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Tfb_v-IHxDpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Main Preprocessing Functions"
      ],
      "metadata": {
        "id": "p0GRz9ruxELU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3nuH5Rsvp7O"
      },
      "outputs": [],
      "source": [
        "def chebyshev_bandpass(lowcut, highcut, fs, order=4, rp=0.5):\n",
        "    \"\"\"\n",
        "    Design a Chebyshev Type I bandpass filter.\n",
        "\n",
        "    Parameters:\n",
        "    - lowcut: Low frequency cut-off for the bandpass filter.\n",
        "    - highcut: High frequency cut-off for the bandpass filter.\n",
        "    - fs: Sampling frequency of the EEG data.\n",
        "    - order: The order of the filter (default: 4).\n",
        "    - rp: Maximum ripple in the passband (default: 0.5 dB).\n",
        "\n",
        "    Returns:\n",
        "    - b, a: Numerator (b) and denominator (a) polynomials of the filter.\n",
        "    \"\"\"\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = cheby1(order, rp, [low, high], btype='band')\n",
        "    return b, a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_single_subject(file_name, data_dir,output_dir,training_dir,test_dir,val_dir,\n",
        "                              n_channels=64, n_timepoints=1500, n_classes=40,\n",
        "                              lowcut=6.0, highcut=90.0, fs=1000,target_fs=250, window_length=250):\n",
        "    \"\"\"\n",
        "    Preprocess EEG data for a single subject, segment into 250-sample windows, and save as .npy files.\n",
        "\n",
        "    Parameters:\n",
        "    - data_dir: Directory containing the .mat file.\n",
        "    - file_name: Name of the .mat file (e.g., \"1.mat\").\n",
        "    - output_dir: Directory to save processed .npy files.\n",
        "    - n_channels: Number of EEG channels (default: 64).\n",
        "    - n_timepoints: Number of time points per trial (default: 1500).\n",
        "    - n_classes: Number of target classes (default: 40).\n",
        "    - lowcut: Low frequency cut-off for Chebyshev bandpass filter (default: 6 Hz).\n",
        "    - highcut: High frequency cut-off for Chebyshev bandpass filter (default: 90 Hz).\n",
        "    - fs: Original sampling frequency of the EEG data (default: 1000 Hz).\n",
        "    - target_fs: Target sampling frequency after downsampling (default: 250 Hz).\n",
        "    - window_length: Length of each segment window in samples (default: 250 samples for 1 second).\n",
        "\n",
        "    Saves:\n",
        "    - Individual .npy files for each segment.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create output directory for the subject\n",
        "    subject_output_dir = os.path.join(output_dir, file_name.split('.')[0])\n",
        "    os.makedirs(subject_output_dir, exist_ok=True)\n",
        "\n",
        "    # Load .mat file\n",
        "    mat_data = loadmat(os.path.join(data_dir, file_name.split('.')[0]))\n",
        "\n",
        "    # Assuming data is stored in 'data' variable with shape [64, 1500, 40, 6]\n",
        "    eeg_data = mat_data['data']  # Shape: [64, 1500, 40, 6]\n",
        "    b, a = chebyshev_bandpass(lowcut, highcut, fs, order=4)  # Define Chebyshev filter\n",
        "\n",
        "    file_counter = 1  # Counter for saved files\n",
        "\n",
        "    # Process each trial\n",
        "    for target_idx in range(eeg_data.shape[2]):  # Iterate over 40 target classes\n",
        "        for block_idx in range(eeg_data.shape[3]):  # Iterate over 6 blocks per target\n",
        "            trial_data = eeg_data[:, :, target_idx, block_idx]  # Shape: [64, 1500]\n",
        "\n",
        "            # Apply bandpass filter\n",
        "            trial_data_filtered = np.zeros_like(trial_data)\n",
        "            for ch in range(n_channels):\n",
        "                trial_data_filtered[ch, :] = filtfilt(b, a, trial_data[ch, :])\n",
        "\n",
        "            # Downsample to target sampling rate\n",
        "            trial_data_downsampled = resample(trial_data_filtered,\n",
        "                                              int(trial_data_filtered.shape[1] * target_fs / fs),\n",
        "                                              axis=1)  # Shape: [64, new_timepoints]\n",
        "\n",
        "            # Segment the trial data into 250-sample windows\n",
        "            for start in range(0, trial_data_downsampled.shape[1] - window_length + 1, window_length):\n",
        "                segment = trial_data_downsampled[:, start:start + window_length]  # Shape: [64, 250]\n",
        "\n",
        "                # Normalize each channel\n",
        "                segment_normalized = (segment - segment.mean(axis=1, keepdims=True)) / segment.std(axis=1, keepdims=True)\n",
        "\n",
        "                # Save segment as .npy file\n",
        "                save_path = os.path.join(subject_output_dir, f\"{file_name.split('.')[0]}_{file_counter}.npy\")\n",
        "                np.save(save_path, {\n",
        "                    'data': segment_normalized,  # Shape: [64, 250]\n",
        "                    'label': target_idx + 1,  # Target label (1-40)\n",
        "                    'block': block_idx + 1,  # Block index (1-6)\n",
        "                    'segment_id': file_counter,  # Segment ID\n",
        "                    'subject_id': file_name.split('.')[0]  # Subject ID from filename\n",
        "                })\n",
        "                file_counter += 1\n",
        "\n",
        "    print(f\"Processed and saved {file_counter - 1} files for subject {file_name.split('.')[0]} in {subject_output_dir}\")\n",
        "\n",
        "    all_files = [os.path.join(subject_output_dir, f) for f in os.listdir(subject_output_dir) if f.endswith('.npy')]\n",
        "    train_files, temp_files = train_test_split(all_files, test_size=0.2)\n",
        "    val_files, test_files = train_test_split(temp_files, test_size=0.5)\n",
        "\n",
        "    # Move files to corresponding folders\n",
        "    for f in train_files:\n",
        "        shutil.move(f, os.path.join(training_dir, os.path.basename(f)))\n",
        "    for f in val_files:\n",
        "        shutil.move(f, os.path.join(val_dir, os.path.basename(f)))\n",
        "    for f in test_files:\n",
        "        shutil.move(f, os.path.join(test_dir, os.path.basename(f)))\n",
        "\n",
        "    print(f\"Split {len(all_files)} files into training ({len(train_files)}), val ({len(val_files)}), and test ({len(test_files)}) folders.\")\n"
      ],
      "metadata": {
        "id": "_uAvu4QyGXYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Preprocessing"
      ],
      "metadata": {
        "id": "Vgx-qyj6xOLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this if datasets are stored in Google Drive\n",
        "import google.colab.drive\n",
        "google.colab.drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6hf3wD8G9Gu",
        "outputId": "2c737c44-a1a6-4216-a567-3f3e4ad59103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose data_dir for raw Benchmark data\n",
        "data_dir = '/content/drive/MyDrive/11785-IDL-Project-Team19/data_1s/raw'\n",
        "\n",
        "# Choose output_dir for preprocessed data\n",
        "output_dir = '/content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/'\n",
        "\n",
        "# Choose directories for the partitioned train-val-test datasets\n",
        "train_dir='/content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/train'\n",
        "test_dir='/content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/test'\n",
        "val_dir='/content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/val'\n",
        "mat_files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]\n",
        "for file_name in mat_files:\n",
        "    preprocess_single_subject(file_name,data_dir , output_dir,train_dir, test_dir,val_dir)"
      ],
      "metadata": {
        "id": "e0z6485Xw6iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb38c7e2-1542-4f2e-9eb1-c9a165f15c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved 240 files for subject S2 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S2\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S3 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S3\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S4 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S4\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S6 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S6\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S7 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S7\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S8 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S8\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S10 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S10\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S11 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S11\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S12 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S12\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S13 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S13\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S14 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S14\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S15 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S15\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S16 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S16\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S17 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S17\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S18 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S18\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S19 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S19\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S21 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S21\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S22 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S22\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S23 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S23\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S24 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S24\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S25 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S25\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S26 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S26\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S27 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S27\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S28 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S28\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S29 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S29\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S30 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S30\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S31 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S31\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S32 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S32\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S33 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S33\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S34 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S34\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S35 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S35\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S5 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S5\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n",
            "Processed and saved 240 files for subject S20 in /content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/prep/S20\n",
            "Split 240 files into training (192), val (24), and test (24) folders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test that preprocessing worked\n",
        "directory = '/content/drive/MyDrive/11785-IDL-Project-Team19/data_4s/train'\n",
        "file_count = sum(1 for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file)))\n",
        "print(f\"Total number of files in the directory: {file_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm0JAJgVHTN5",
        "outputId": "8d4c1048-81fc-4762-e186-15fe57c207d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of files in the directory: 6336\n"
          ]
        }
      ]
    }
  ]
}